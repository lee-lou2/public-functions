import time

import speech_recognition as sr
from openai import OpenAI
from pydub import AudioSegment
from pydub.playback import play

OPENAI_API_KEY = ""
client = OpenAI(api_key=OPENAI_API_KEY)


def tts(text):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    response = client.audio.speech.create(model="tts-1", voice="alloy", input=text)
    response.stream_to_file("output.mp3")
    song = AudioSegment.from_file("output.mp3", format="mp3")
    play(song)


def stt():
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    r = sr.Recognizer()
    with sr.Microphone() as source:
        audio = r.listen(source, timeout=10, phrase_time_limit=30)
        return r.recognize_whisper_api(audio, api_key=OPENAI_API_KEY)


def conversation(message: str):
    """AI ì™€ ëŒ€í™”"""
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "user", "content": message}]
    )
    return response.choices[0].message.content


if __name__ == "__main__":
    while True:
        print("ğŸ™ï¸ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤")
        text = stt()
        if text:
            print("ğŸ‘¨ ì‚¬ìš©ì ì§ˆë¬¸ : ", text)
            answer = conversation(text)
            print("ğŸ¤– ChatGPT ë‹µë³€ : ", answer)
            tts(conversation(text))
        else:
            print("ğŸ‘¨ ì‚¬ìš©ì ì§ˆë¬¸ê°€ ì—†ìŠµë‹ˆë‹¤")
            time.sleep(1)
