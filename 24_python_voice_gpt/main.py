import os
import time

import speech_recognition as sr
from openai import OpenAI
from pydub import AudioSegment
from pydub.playback import play

OPENAI_API_KEY = ""
# OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
client = OpenAI(api_key=OPENAI_API_KEY)


def tts(text):
    """ν…μ¤νΈλ¥Ό μμ„±μΌλ΅ λ³€ν™"""
    # μμ„Έν• λ‚΄μ© : https://platform.openai.com/docs/guides/text-to-speech
    response = client.audio.speech.create(model="tts-1", voice="alloy", input=text)
    response.stream_to_file("output.mp3")
    song = AudioSegment.from_file("output.mp3", format="mp3")
    play(song)


def stt():
    """μμ„±μ„ ν…μ¤νΈλ΅ λ³€ν™"""
    # μμ„Έν• λ‚΄μ© : https://github.com/Uberi/speech_recognition
    r = sr.Recognizer()
    with sr.Microphone() as source:
        audio = r.listen(source, timeout=10, phrase_time_limit=30)
        return r.recognize_whisper_api(audio, api_key=OPENAI_API_KEY)


def conversation(message: str):
    """AI μ™€ λ€ν™”"""
    # μμ„Έν• λ‚΄μ© : https://platform.openai.com/docs/guides/text-generation
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "user", "content": message}]
    )
    return response.choices[0].message.content


if __name__ == "__main__":
    while True:
        print("π™οΈ λ…Ήμμ„ μ‹μ‘ν•©λ‹λ‹¤")
        text = stt()
        if text:
            print("π‘¨ μ‚¬μ©μ μ§λ¬Έ : ", text)
            answer = conversation(text)
            print("π¤– ChatGPT λ‹µλ³€ : ", answer)
            tts(conversation(text))
        else:
            print("π‘¨ μ‚¬μ©μ μ§λ¬Έκ°€ μ—†μµλ‹λ‹¤")
            time.sleep(1)
